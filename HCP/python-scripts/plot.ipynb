{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/data/users2/jwardell1/undersampling-project/HCP/pkl-files'\n",
    "joined_files = os.path.join(pkl_dir, 'sr1_*.pkl')\n",
    "joined_list = glob.glob(joined_files)\n",
    "sr1_df = pd.concat(map(pd.read_pickle, joined_list), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_no</th>\n",
       "      <th>noise_no</th>\n",
       "      <th>snr</th>\n",
       "      <th>scalar</th>\n",
       "      <th>classifier</th>\n",
       "      <th>test_scores</th>\n",
       "      <th>target</th>\n",
       "      <th>predictions</th>\n",
       "      <th>test_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.354813</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0         1.0\n",
       "1         1.0\n",
       "2         1.0\n",
       "3   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.001208\n",
       "1       0.003028\n",
       "2       0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.354813</td>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>0    0.999453\n",
       "1    0.998495\n",
       "2         1.0\n",
       "3   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       6.938395e-05\n",
       "1       1.255395e-04\n",
       "2   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.354813</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0    0.971135\n",
       "1    0.961286\n",
       "2    0.985499\n",
       "3   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0        0.000000e+00\n",
       "1        1.331369e-73\n",
       "2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.354813</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0    0.999863\n",
       "1    0.998085\n",
       "2         1.0\n",
       "3   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.001565\n",
       "1       0.003808\n",
       "2       0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.354813</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0         1.0\n",
       "1         1.0\n",
       "2         1.0\n",
       "3   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.001208\n",
       "1       0.003028\n",
       "2       0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11595</th>\n",
       "      <td>86</td>\n",
       "      <td>98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0         1.0\n",
       "1     0.99959\n",
       "2         1.0\n",
       "3   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.001517\n",
       "1       0.002157\n",
       "2       0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11596</th>\n",
       "      <td>86</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.021717\n",
       "1       0.039269\n",
       "2       0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11597</th>\n",
       "      <td>86</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>0         1.0\n",
       "1    0.999316\n",
       "2         1.0\n",
       "3   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       3.909833e-08\n",
       "1       1.678257e-05\n",
       "2   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11598</th>\n",
       "      <td>86</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0    0.974145\n",
       "1    0.965663\n",
       "2    0.986731\n",
       "3   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0        0.000000e+00\n",
       "1       4.316405e-161\n",
       "2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11599</th>\n",
       "      <td>86</td>\n",
       "      <td>99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0         1.0\n",
       "1     0.99959\n",
       "2         1.0\n",
       "3   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.001517\n",
       "1       0.002157\n",
       "2       0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11600 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       graph_no  noise_no  snr    scalar             classifier  \\\n",
       "0            65         0  0.9  0.354813    Logistic Regression   \n",
       "1            65         0  0.9  0.354813  Multilayer Perceptron   \n",
       "2            65         0  0.9  0.354813            Naive Bayes   \n",
       "3            65         0  0.9  0.354813                    SVM   \n",
       "4            65         1  0.9  0.354813    Logistic Regression   \n",
       "...         ...       ...  ...       ...                    ...   \n",
       "11595        86        98  1.0  0.316228                    SVM   \n",
       "11596        86        99  1.0  0.316228    Logistic Regression   \n",
       "11597        86        99  1.0  0.316228  Multilayer Perceptron   \n",
       "11598        86        99  1.0  0.316228            Naive Bayes   \n",
       "11599        86        99  1.0  0.316228                    SVM   \n",
       "\n",
       "                                             test_scores  \\\n",
       "0      0         1.0\n",
       "1         1.0\n",
       "2         1.0\n",
       "3   ...   \n",
       "1      0    0.999453\n",
       "1    0.998495\n",
       "2         1.0\n",
       "3   ...   \n",
       "2      0    0.971135\n",
       "1    0.961286\n",
       "2    0.985499\n",
       "3   ...   \n",
       "3      0    0.999863\n",
       "1    0.998085\n",
       "2         1.0\n",
       "3   ...   \n",
       "4      0         1.0\n",
       "1         1.0\n",
       "2         1.0\n",
       "3   ...   \n",
       "...                                                  ...   \n",
       "11595  0         1.0\n",
       "1     0.99959\n",
       "2         1.0\n",
       "3   ...   \n",
       "11596  0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "11597  0         1.0\n",
       "1    0.999316\n",
       "2         1.0\n",
       "3   ...   \n",
       "11598  0    0.974145\n",
       "1    0.965663\n",
       "2    0.986731\n",
       "3   ...   \n",
       "11599  0         1.0\n",
       "1     0.99959\n",
       "2         1.0\n",
       "3   ...   \n",
       "\n",
       "                                                  target  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "11595  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11596  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11597  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11598  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11599  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                             predictions  \\\n",
       "0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                  ...   \n",
       "11595  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11596  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11597  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11598  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11599  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              test_proba  \n",
       "0      0       0.001208\n",
       "1       0.003028\n",
       "2       0.00...  \n",
       "1      0       6.938395e-05\n",
       "1       1.255395e-04\n",
       "2   ...  \n",
       "2      0        0.000000e+00\n",
       "1        1.331369e-73\n",
       "2 ...  \n",
       "3      0       0.001565\n",
       "1       0.003808\n",
       "2       0.00...  \n",
       "4      0       0.001208\n",
       "1       0.003028\n",
       "2       0.00...  \n",
       "...                                                  ...  \n",
       "11595  0       0.001517\n",
       "1       0.002157\n",
       "2       0.00...  \n",
       "11596  0       0.021717\n",
       "1       0.039269\n",
       "2       0.02...  \n",
       "11597  0       3.909833e-08\n",
       "1       1.678257e-05\n",
       "2   ...  \n",
       "11598  0        0.000000e+00\n",
       "1       4.316405e-161\n",
       "2 ...  \n",
       "11599  0       0.001517\n",
       "1       0.002157\n",
       "2       0.00...  \n",
       "\n",
       "[11600 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc(classifier_df):\n",
    "# Remove rows with NaN values in 'test_proba'\n",
    "   classifier_df = classifier_df.dropna(subset=['test_proba'])\n",
    "\n",
    "   # Loop through each row\n",
    "   for index, row in classifier_df.iterrows():\n",
    "      # Extract true labels and predicted probabilities\n",
    "      true_labels = row['target']\n",
    "      predicted_proba = row['test_proba']\n",
    "      if not pd.notna(row['test_proba']).all():\n",
    "         print(f\"Skipping '{row['classifier']}' classifier due to NaN values in 'test_proba'.\")\n",
    "         continue\n",
    "         \n",
    "      # Calculate fpr, tpr, and thresholds\n",
    "      fpr, tpr, thresholds = roc_curve(true_labels, predicted_proba)\n",
    "      roc_auc = auc(fpr, tpr)\n",
    "\n",
    "      # Append AUC value to the row\n",
    "      classifier_df.at[index, 'auc'] = roc_auc\n",
    "      classifier_df.at[index, 'nstd'] = 1.0\n",
    "\n",
    "   return classifier_df\n",
    "\n",
    "# Define the plot_save_roc_curves_for_classifiers function\n",
    "def calculate_auc_for_classifiers(data):\n",
    "   \"\"\"\n",
    "   Calculate AUC values for classifiers in each DataFrame.\n",
    "\n",
    "   Args:\n",
    "   - data (DataFrame): DataFrame containing classifier data.\n",
    "\n",
    "   Returns:\n",
    "   - data_with_auc (DataFrame): DataFrame with appended 'auc' column containing AUC values.\n",
    "   \"\"\"\n",
    "   data_with_auc = pd.DataFrame()\n",
    "\n",
    "   for classifier_name, classifier_df in data.groupby('classifier'):\n",
    "   # Skip classifiers with NaN values in 'test_proba'\n",
    "      if classifier_df['test_proba'].isnull().any():\n",
    "         print(f\"Skipping '{classifier_name}' classifier due to NaN values in 'test_proba'.\")\n",
    "         continue\n",
    "   \n",
    "      # Calculate AUC for the classifier\n",
    "      classifier_df = calculate_auc(classifier_df)\n",
    "      data_with_auc = pd.concat([data_with_auc, classifier_df])\n",
    "\n",
    "   return data_with_auc\n",
    "\n",
    "def save_auc_vs_noise_plots_to_pwd(df1, df2, df3, df4, lower_limit=None):\n",
    "   # Group the dataframes by classifier\n",
    "   grouped1 = df1.groupby('classifier')\n",
    "   grouped2 = df2.groupby('classifier')\n",
    "   grouped3 = df3.groupby('classifier')\n",
    "   grouped4 = df4.groupby('classifier')\n",
    "   \n",
    "\n",
    "\n",
    "   # Plot AUC vs noise level for each classifier and sampling rate and save the plots to the current working directory\n",
    "   for name, group1 in grouped1:\n",
    "      plt.figure(figsize=(10, 6))  # Adjust size of the plot if needed\n",
    "      for idx, (label, data1) in enumerate(group1.groupby('nstd')):\n",
    "         if lower_limit is None:\n",
    "            plt.plot(data1['snr'], data1['auc'], marker='o', linestyle='-', color='green', label='TR=SR1')\n",
    "         else:\n",
    "            data_filtered = data1[data1['snr'] >= lower_limit]\n",
    "            plt.plot(data_filtered['snr'], data_filtered['auc'], marker='o', linestyle='-', color='green', label='TR=SR1')\n",
    "\n",
    "         \n",
    "      \n",
    "      # Add data from df2\n",
    "      for idx, (label, data2) in enumerate(grouped2.get_group(name).groupby('nstd')):\n",
    "         if lower_limit is None:\n",
    "            plt.plot(data2['snr'], data2['auc'], marker='s', linestyle='--', color='red', label='TR=SR2')\n",
    "         else:\n",
    "            data_filtered = data2[data2['snr'] >= lower_limit]\n",
    "            plt.plot(data_filtered['snr'], data_filtered['auc'], marker='s', linestyle='--', color='red', label='TR=SR2')\n",
    "\n",
    "      # Add data from df3\n",
    "      for idx, (label, data3) in enumerate(grouped3.get_group(name).groupby('nstd')):\n",
    "         if lower_limit is None:\n",
    "            plt.plot(data3['snr'], data3['auc'], marker='^', linestyle='-.', color='blue', label='Concat')\n",
    "         else:\n",
    "            data_filtered = data3[data3['snr'] >= lower_limit]\n",
    "            plt.plot(data_filtered['snr'], data_filtered['auc'], marker='^', linestyle='-.', color='blue', label='Concat')\n",
    "      \n",
    "      # Add data from df4\n",
    "      for idx, (label, data4) in enumerate(grouped4.get_group(name).groupby('nstd')):\n",
    "         if lower_limit is None:\n",
    "            plt.plot(data4['snr'], data4['auc'], marker='x', linestyle=':', color='purple', label='Add')\n",
    "         else:\n",
    "            data_filtered = data4[data4['snr'] >= lower_limit]\n",
    "            plt.plot(data_filtered['snr'], data_filtered['auc'], marker='x', linestyle=':', color='purple', label='Add')\n",
    "\n",
    "\n",
    "      plt.xlabel('SNR')\n",
    "      plt.ylabel('AUC')\n",
    "      plt.title(f'AUC vs SNR for {name}')\n",
    "      plt.legend()\n",
    "      plt.grid(True)\n",
    "      plt.savefig(f'add_all_auc_vs_snr_{name}.png')  # Save the plot as an image file in the current working directory\n",
    "      plt.close()\n",
    "\n",
    "# Usage example:\n",
    "# save_auc_vs_noise_plots_to_pwd(sr1_with_auc, sr2_with_auc, concat_with_auc, 'Combined')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_dir = '/data/users2/jwardell1/undersampling-project/HCP/pkl-files'\n",
    "joined_files = os.path.join(pkl_dir, 'sr1_*.pkl')\n",
    "joined_list = glob.glob(joined_files)\n",
    "sr1 = pd.concat(map(pd.read_pickle, joined_list), ignore_index=True)\n",
    "\n",
    "\n",
    "joined_files = os.path.join(pkl_dir, 'sr2_*.pkl')\n",
    "joined_list = glob.glob(joined_files)\n",
    "sr2 = pd.concat(map(pd.read_pickle, joined_list), ignore_index=True)\n",
    "\n",
    "joined_files = os.path.join(pkl_dir, 'concat_*.pkl')\n",
    "joined_list = glob.glob(joined_files)\n",
    "concat = pd.concat(map(pd.read_pickle, joined_list), ignore_index=True)\n",
    "\n",
    "\n",
    "joined_files = os.path.join(pkl_dir, 'add_*.pkl')\n",
    "joined_list = glob.glob(joined_files)\n",
    "add = pd.concat(map(pd.read_pickle, joined_list), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1_with_auc = calculate_auc_for_classifiers(sr1)\n",
    "sr2_with_auc = calculate_auc_for_classifiers(sr2)\n",
    "concat_with_auc = calculate_auc_for_classifiers(concat)\n",
    "add_with_auc = calculate_auc_for_classifiers(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_auc_vs_noise_plots_to_pwd(sr1_with_auc, sr2_with_auc, concat_with_auc, add_with_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['graph_no', 'noise_no', 'snr', 'scalar', 'classifier', 'test_scores',\n",
       "       'target', 'predictions', 'test_proba'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1 = pd.read_pickle('/data/users2/jwardell1/undersampling-project/OULU/pkl-files/sr1_0.85_1000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>graph_no</th>\n",
       "      <th>noise_no</th>\n",
       "      <th>snr</th>\n",
       "      <th>scalar</th>\n",
       "      <th>classifier</th>\n",
       "      <th>test_scores</th>\n",
       "      <th>target</th>\n",
       "      <th>predictions</th>\n",
       "      <th>test_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0       0.887446\n",
       "1       0.937888\n",
       "2        0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0       0.811263\n",
       "1       0.945977\n",
       "2       0.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0        1.0\n",
       "1        0.5\n",
       "2        1.0\n",
       "3    0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.329813\n",
       "1       0.334387\n",
       "2       0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0       0.887446\n",
       "1       0.937888\n",
       "2        0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0       0.811263\n",
       "1       0.945977\n",
       "2       0.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0        1.0\n",
       "1        0.5\n",
       "2        1.0\n",
       "3    0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.329813\n",
       "1       0.334387\n",
       "2       0.35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0       0.887446\n",
       "1       0.937888\n",
       "2        0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>Multilayer Perceptron</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0       0.811263\n",
       "1       0.945977\n",
       "2       0.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0        1.0\n",
       "1        0.5\n",
       "2        1.0\n",
       "3    0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.375837</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0       0.329813\n",
       "1       0.334387\n",
       "2       0.35...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    graph_no  noise_no   snr    scalar             classifier  \\\n",
       "0       1000         0  0.85  0.375837    Logistic Regression   \n",
       "1       1000         0  0.85  0.375837  Multilayer Perceptron   \n",
       "2       1000         0  0.85  0.375837            Naive Bayes   \n",
       "3       1000         0  0.85  0.375837                    SVM   \n",
       "4       1000         1  0.85  0.375837    Logistic Regression   \n",
       "5       1000         1  0.85  0.375837  Multilayer Perceptron   \n",
       "6       1000         1  0.85  0.375837            Naive Bayes   \n",
       "7       1000         1  0.85  0.375837                    SVM   \n",
       "8       1000         2  0.85  0.375837    Logistic Regression   \n",
       "9       1000         2  0.85  0.375837  Multilayer Perceptron   \n",
       "10      1000         2  0.85  0.375837            Naive Bayes   \n",
       "11      1000         2  0.85  0.375837                    SVM   \n",
       "\n",
       "                                          test_scores  \\\n",
       "0   0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "1   0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "2   0        1.0\n",
       "1        0.5\n",
       "2        1.0\n",
       "3    0....   \n",
       "3   0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "4   0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "5   0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "6   0        1.0\n",
       "1        0.5\n",
       "2        1.0\n",
       "3    0....   \n",
       "7   0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "8   0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "9   0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "10  0        1.0\n",
       "1        0.5\n",
       "2        1.0\n",
       "3    0....   \n",
       "11  0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5...   \n",
       "\n",
       "                                               target  \\\n",
       "0   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                          predictions  \\\n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "5   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "10  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "11  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           test_proba  \n",
       "0   0       0.887446\n",
       "1       0.937888\n",
       "2        0.9...  \n",
       "1   0       0.811263\n",
       "1       0.945977\n",
       "2       0.93...  \n",
       "2   0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....  \n",
       "3   0       0.329813\n",
       "1       0.334387\n",
       "2       0.35...  \n",
       "4   0       0.887446\n",
       "1       0.937888\n",
       "2        0.9...  \n",
       "5   0       0.811263\n",
       "1       0.945977\n",
       "2       0.93...  \n",
       "6   0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....  \n",
       "7   0       0.329813\n",
       "1       0.334387\n",
       "2       0.35...  \n",
       "8   0       0.887446\n",
       "1       0.937888\n",
       "2        0.9...  \n",
       "9   0       0.811263\n",
       "1       0.945977\n",
       "2       0.93...  \n",
       "10  0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0....  \n",
       "11  0       0.329813\n",
       "1       0.334387\n",
       "2       0.35...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5    1.0\n",
       "6    1.0\n",
       "7    1.0\n",
       "8    1.0\n",
       "9    1.0\n",
       "Name: (SVM, test), dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr1.iloc[11]['test_scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
